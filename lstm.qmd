---
title: "LSTM - Long Short-Term Memory"
format:
  html:
    code-fold: False
jupyter: python3
---

# ğŸ§  LSTM Theory

LSTMs are a type of Recurrent Neural Network capable of learning long-term dependencies. Useful in time series, NLP, and sequential tasks.

---

# âš™ï¸ Architecture Diagram

```{mermaid}
graph TD;
    Input --> LSTMCell[LSTM Cell]
    LSTMCell --> Output
    LSTMCell --> Memory[Memory State]
```

---

# ğŸ§ª Interactive Demo

```{python}
import ipywidgets as widgets
import torch
import torch.nn as nn

input_size = widgets.IntSlider(value=8, min=1, max=32, description='Input size')
display(input_size)

lstm = nn.LSTM(input_size=input_size.value, hidden_size=20, num_layers=2)
x = torch.randn(5, 3, input_size.value)
h0 = torch.randn(2, 3, 20)
c0 = torch.randn(2, 3, 20)
out, _ = lstm(x, (h0, c0))
out.shape
```

---

# ğŸ“ Quick Quiz

::: {.quiz}
### What is the core strength of LSTMs?

1. Static image classification  
2. Learning long-term dependencies  
3. Simple math operations  
:::
